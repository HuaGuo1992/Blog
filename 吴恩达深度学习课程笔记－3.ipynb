{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2018-2-10\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Course 4 Convolutional Neutral Network (Part A)\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这是本系列课程的第四门课程,这门课程主要介绍卷积神经网络,其先介绍了卷积神经网络基础知识,后重点介绍了几个已有的成熟的神经网络模型,之后课程将注意力关注于物体检测,人脸识别和风格迁移等实际应用层面.\n",
    "\n",
    "这个课程被分为三篇博客介绍, 此篇博客主要介绍卷积神经网络基础和图像分类算法."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将解决的问题\n",
    "--\n",
    "本节课中要解决的计算机视觉问题有三个：\n",
    "+ 图像分类(image classificator)\n",
    "+ 物体检测(Object detection)\n",
    "+ 神经风格迁移(Neutral style transfer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "卷积神经网络基础\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**边缘检测问题**\n",
    "\n",
    "如下图，可以用特定的滤波器(filter)来实现图像中边缘检测问题，进而引出**卷积**\n",
    "\n",
    "<img src='images/edge_detection.png' width='800' height='600'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Padding & Stridding**\n",
    "\n",
    "无padding的标准卷积的缺点:\n",
    "+ 输出网格变小\n",
    "+ 损失一些信息,特别是边缘信息\n",
    "\n",
    "Valid and same convolution:\n",
    "+ valid:  (n, n)\\*(f, f) $\\longrightarrow$ (n-f+1, n-f+1)\n",
    "+ same:  Input size = output size\n",
    "\n",
    "最终维度为:\n",
    "\n",
    "(n, n) image, padding p, (f, f) filter, $\\longrightarrow$ ($\\frac{n+2p-f}{s} + 1$, $\\frac{n+2p-f}{s} + 1$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**卷积神经网络中的层**\n",
    "\n",
    "1. Convolution (CoNN)\n",
    "2. Pooling (POOL)\n",
    "3. Fully Connected (FC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pooling Layer**\n",
    "\n",
    "分为max pooling 和 average pooling. 无参数.-\n",
    "步幅为m, 则输出为n/m\n",
    "\n",
    "**Pooling layer 的作用???**\n",
    "\n",
    "**卷积(convolution)和互相关(cross-correlation)**\n",
    "\n",
    "神经网络中的卷积在**数字图像处理**中实际为互相关,而实际的卷积运算会对核(Kernel)进行翻转.由于**惯例**,神经网络中称为卷积\n",
    "\n",
    "<img src='images/cross_correlation.png' width='800' height='600'>\n",
    "\n",
    "**为什么选用卷积**\n",
    "\n",
    "课程中解释了两个优点:\n",
    "+ 参数共享: 每个特征会被多次利用, 同时参数数量相对fullly connected减少很多\n",
    "+ 稀疏连接: 每个输出只赖于部分输入参数, 减少过拟合."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "图片识别CNN实例研究和实用建议\n",
    "--\n",
    "\n",
    "本节研究的实例主要有:\n",
    "\n",
    "+ 经典实例\n",
    "    + LeNet-5\n",
    "    + AlexNet\n",
    "    + VGG\n",
    "+ Redidual Network (ResNet)\n",
    "+ Inception neutral network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**经典实例**\n",
    "\n",
    "LeNet 最初用于识别数字.它的基本结构为Input layer -> CNN layer -> Pooling layer -> CNN layer -> Pooling layer -> FC layer -> FC layer -> Output layer. 大约有6万个参数.\n",
    "\n",
    "<img src='images/LeNet.png' width = '800'>\n",
    "\n",
    "模型提出时池化层采用average pool, 各激活层采用Sigmoid和tanh函数."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AlexNet 结构比LeNet复杂.大约有6千万个参数.\n",
    "\n",
    "<img src='images/AlexNet.png' width='800'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG结构使用了固定的CNN层和Pooling层, 包含一亿三千万的参数:\n",
    "\n",
    "CONV = (3, 3) filter, s=1, same\n",
    "\n",
    "MAX-POOL = (2, 2), s=2\n",
    "\n",
    "<img src='images/VGG.png' width='800'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ResNet(residual network 残差神经网络)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面展示了一个**普通神经网络**中的残差模块:\n",
    "<img src='images/residual_block.png' width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如上图, 相当于有一个捷径, 从$a^{[l]}$直接连接到$a^{[l+2]}$之前, 公式$$a^{[l+1]} = g(z^{[l+2]} + a^{[l]})$$ 取代了公式  $a^{[l+2]}=g(z^{[l+2]})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在图片识别中的残差神经网络如下图, 由上面的公式易知, 需要保证$a^{[l]}$和$z^{[l+2]}$的维度相同, 于是在CNN大多使用**same convolution**. 一般结构为 Input layer -> CNN -> CNN -> POOL.....-> output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/plain_vs_resnet.png' width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同时介绍了使用残差神经网络的优点:随着神经网络越来越深, 原因为梯度消失. 其效率受到限制, 运用resnet可以提高效果, 如下图\n",
    "<img src='images/res.png.png' width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inception Network\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inception network 的初始想法是将多种网络层同时用上, 如下图\n",
    "<img src='images/inception_motivation.png' width=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同时在Inception network中使用了**(1, 1)的卷积层**,用来压缩输入参数的第三个维度, 进而大大减少参数, 减少计算量. 如下为其作用展示:\n",
    "<img src='images/1*1_convolution.png', width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下图为一个**Inception 模块**, 多个模块可构成一个大的inception网络\n",
    "<img src='images/inception_module.png' width=600>\n",
    "Inception Network\n",
    "<img src='images/inception_network.png' width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**图片识别实用建议**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 使用已有的开源的神经网络结构来开始你的项目\n",
    "2. 迁移学习, 使用别人已经训练好的权重然后根据需要进行调整, 如下图:\n",
    "<img src='images/transfer_learning.jpg' width=800>\n",
    "3. 数据扩充(对于计算机视觉问题):\n",
    "    + 计算机视觉会碰到数据不足的问题, 可用以下方法进行数据扩充: 镜像, 随机切割, 颜色调整\n",
    "\n",
    "课程中也提到了对于参加竞赛的一些建议:\n",
    "1. 集成(ensembling): 训练多个模型, 平均计算结果\n",
    "2. 测试时对照片进行多种切割, 如下:\n",
    "<img src='images/bechmark.png' width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**计算机视觉现状**\n",
    "下图展示了数据量大小和手动调参工作的关系:\n",
    "<img src='images/state_of_art.jpg' width=800>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
