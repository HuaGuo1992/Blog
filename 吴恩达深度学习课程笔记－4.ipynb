{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2018.2.10\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course 4 Convolutional Neutral Network (Part B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这是本系列课程的第四门课程,这门课程主要介绍卷积神经网络,其先介绍了卷积神经网络基础知识,后重点介绍了几个已有的成熟的神经网络模型,之后课程将注意力关注于物体检测,人脸识别和风格迁移等实际应用层面.\n",
    "\n",
    "这个课程被分为三篇博客介绍, 此篇博客主要介绍目标检测问题. 这节前面先介绍了YOLO算法的细节技术, 然后拼装在一起实现了YOLO算法, 最后介绍了目标检测的另外一个思路:候选区域(region proposal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "课程中提到YOLO论文是一篇比较难的文献. 这个算法看了好久才看明白咋回事."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 目标定位和目标检测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下图展示了三个问题:图像分类, 带有定位的图像分类和目标检测. 前两者图中有一个物体, 而后者图中有多个物体\n",
    "<img src='images/localization_detection.png' width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Target label**\n",
    "\n",
    "下图我们重新定义了图像检测的输出: 第一项 是否为物体, 后四项 物体的定位坐标, 最后三项 是个物体的概率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/target_label.png' width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "滑动窗口检测(Sliding windows detection)\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "滑动窗口检测如下图:\n",
    "<img src='images/sliding_windows_detection.png' width=800>\n",
    "\n",
    "1. 小窗口输入卷积神经网络, 判断是否有物体, \n",
    "2. 滑动窗口, 一个个输入检测\n",
    "3. 增大窗口检测\n",
    "\n",
    "**缺点:** 计算量过大."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**全连接层变为卷积层**\n",
    "\n",
    "<img src='images/fc2con.png' width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**滑动窗口检测的卷积实现**\n",
    "\n",
    "滑动窗口检测中会有窗口共享参数, 为简化计算自然想到卷积实现, 如下图:\n",
    "\n",
    "<img src='images/con_implementation.png' width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "依照上面的办法, 不需进行窗口分割, 直接将图片输入卷积层, 便能得到结果, 大大提高整体计算效率\n",
    "<img src='images/con_sliding.png' width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bounding Box 预测\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "之前的卷积形式的滑动窗口算法无法输出精确的边界框, 下面展示YOLO算法:\n",
    "<img src='images/yolo.png' width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先介绍YOLO算法中如何标注**训练集**:\n",
    "\n",
    "+ 将对象分配到对象中点所在网格中\n",
    "+ 其标签包含信息为以比例表示的中点坐标和长宽, 如下图:\n",
    "<img src='images/specify_box.png' width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOLO是一次单次卷积实现, 算法实现效率高, 运行速度快, 可以实时识别**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "交并比(Intersection-over-union)\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "交并比是用来评估目标定位的.\n",
    "\n",
    "$$IoU = \\frac{sizeof交}{size of 并}$$\n",
    "<img src='images/IoU.png' width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "非极值压缩算法(non-max supression algorith)\n",
    "--\n",
    "\n",
    "如下图, 在上面YOLO算法中, 可能出现多网格检测出一个物体\n",
    "<img src='images/nms1.png' width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如下图, \n",
    "<img src='images/nms2.png' width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NMS算法思想如下(**对于一类物体**):\n",
    "\n",
    "1. 输出预测, 如上图\n",
    "2. 删除所有概率小于0.6的\n",
    "3. 当仍有边框未被处理时,进行下面算法(有多辆车时会多次进行):\n",
    "    + 选一个最大概率, 输出这个边框\n",
    "    + 删除所有和这个边框IoU> 0.5 的边框(删除重复的), 返回上一步"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOLO算法实例展示(拼装上述技术)\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**输入和预测**\n",
    "\n",
    "+ 图片输入为(100, 100, 3)划分为9\\*9的网格\n",
    "+ 包含三种物体: 行人, 车和摩托车,两个anchor: 行人和车, 则输出y维度为(3, 3, 2, 8)或(3, 3, 16)\n",
    "\n",
    "<img src='images/training.png' width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**输出非极大值抑制结果**\n",
    "\n",
    "输入图片如下:\n",
    "<img src='images/out1.png' width=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "进行预测, 得到(3, 3, 2, 8)输入, 将边框标在图上\n",
    "<img src='images/out2.png' width=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一步, 直接去除概率小于0.6的边框, 如下\n",
    "<img src='images/out3.png' width=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二步, 对行人, 汽车, 摩托车这三类边框分别进行非极值压缩算法, 最终输出如下:\n",
    "\n",
    "<img src='images/out4.png' width=300>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
