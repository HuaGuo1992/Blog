{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>内容目录<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#前言\" data-toc-modified-id=\"前言-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>前言</a></span></li><li><span><a href=\"#决策树算法\" data-toc-modified-id=\"决策树算法-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>决策树算法</a></span><ul class=\"toc-item\"><li><span><a href=\"#实验\" data-toc-modified-id=\"实验-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>实验</a></span><ul class=\"toc-item\"><li><span><a href=\"#实验数据\" data-toc-modified-id=\"实验数据-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>实验数据</a></span></li><li><span><a href=\"#信息熵和信息增益\" data-toc-modified-id=\"信息熵和信息增益-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>信息熵和信息增益</a></span></li><li><span><a href=\"#最大信息增益特征\" data-toc-modified-id=\"最大信息增益特征-2.1.3\"><span class=\"toc-item-num\">2.1.3&nbsp;&nbsp;</span>最大信息增益特征</a></span></li><li><span><a href=\"#id3算法\" data-toc-modified-id=\"id3算法-2.1.4\"><span class=\"toc-item-num\">2.1.4&nbsp;&nbsp;</span>id3算法</a></span></li><li><span><a href=\"#预测新数据\" data-toc-modified-id=\"预测新数据-2.1.5\"><span class=\"toc-item-num\">2.1.5&nbsp;&nbsp;</span>预测新数据</a></span></li><li><span><a href=\"#辅助函数\" data-toc-modified-id=\"辅助函数-2.1.6\"><span class=\"toc-item-num\">2.1.6&nbsp;&nbsp;</span>辅助函数</a></span></li></ul></li><li><span><a href=\"#实战\" data-toc-modified-id=\"实战-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>实战</a></span><ul class=\"toc-item\"><li><span><a href=\"#划分数据和模型拟合\" data-toc-modified-id=\"划分数据和模型拟合-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>划分数据和模型拟合</a></span></li><li><span><a href=\"#模型衡量标准\" data-toc-modified-id=\"模型衡量标准-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>模型衡量标准</a></span></li><li><span><a href=\"#调参解决过拟合\" data-toc-modified-id=\"调参解决过拟合-2.2.3\"><span class=\"toc-item-num\">2.2.3&nbsp;&nbsp;</span>调参解决过拟合</a></span></li></ul></li></ul></li><li><span><a href=\"#随机森林算法\" data-toc-modified-id=\"随机森林算法-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>随机森林算法</a></span><ul class=\"toc-item\"><li><span><a href=\"#1VS2\" data-toc-modified-id=\"1VS2-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>1VS2</a></span></li><li><span><a href=\"#样本的随机和特征的随机\" data-toc-modified-id=\"样本的随机和特征的随机-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>样本的随机和特征的随机</a></span></li><li><span><a href=\"#解决过拟合\" data-toc-modified-id=\"解决过拟合-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>解决过拟合</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前言 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "决策树算法实际上就是寻找最纯净的划分方法. 可以处理分类问题和回归问题.随机森林方法的思想是将多个决策树的结果集合在一起. 采用的?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "决策树算法容易出现过拟合的结果, 因此需要进行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本项目目的为预测样本是否能达到高工资(high income), 为一个二元分类问题."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 决策树算法 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "决策树算法是一个树状的决策图, 是直观的运用统计概率分析的图法. 它表示**对象属性到对象的映射**, 对一个样本来说就是从它的所有特征值到所需预测结果的映射. 树的每个节点表示某个特征的判断条件, 分支表示符合节点条件的对象. **树的叶子节点表示预测结果**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在多个特征存在的情况下, 需要决定特征被考虑的次序, 即分割的特征次序. 常见决策树算法中都选取一个量作为衡量标准, 如id3算法选用信息增益作为不纯度, C4.5算法选用信息增益率作为不纯度, CART算法采用基尼系数作为不纯度."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "了解数据和数据工程, 将category数据转化为数字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================\n",
      "Dataset info before:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 15 columns):\n",
      "age               32561 non-null int64\n",
      "workclass         32561 non-null object\n",
      "fnlwgt            32561 non-null int64\n",
      "education         32561 non-null object\n",
      "education_num     32561 non-null int64\n",
      "marital_status    32561 non-null object\n",
      "occupation        32561 non-null object\n",
      "relationship      32561 non-null object\n",
      "race              32561 non-null object\n",
      "sex               32561 non-null object\n",
      "capital_gain      32561 non-null int64\n",
      "capital_loss      32561 non-null int64\n",
      "hours_per_week    32561 non-null int64\n",
      "native_country    32561 non-null object\n",
      "high_income       32561 non-null object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 3.7+ MB\n",
      "None\n",
      "==============\n",
      "\n",
      "==================\n",
      "Dataset info after:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 15 columns):\n",
      "age               32561 non-null int64\n",
      "workclass         32561 non-null int8\n",
      "fnlwgt            32561 non-null int64\n",
      "education         32561 non-null int8\n",
      "education_num     32561 non-null int64\n",
      "marital_status    32561 non-null int8\n",
      "occupation        32561 non-null int8\n",
      "relationship      32561 non-null int8\n",
      "race              32561 non-null int8\n",
      "sex               32561 non-null int8\n",
      "capital_gain      32561 non-null int64\n",
      "capital_loss      32561 non-null int64\n",
      "hours_per_week    32561 non-null int64\n",
      "native_country    32561 non-null int8\n",
      "high_income       32561 non-null int8\n",
      "dtypes: int64(6), int8(9)\n",
      "memory usage: 1.8 MB\n",
      "None\n",
      "==============\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guohua/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: FutureWarning: Categorical.from_array is deprecated, use Categorical instead\n",
      "/home/guohua/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:22: FutureWarning: Categorical.from_array is deprecated, use Categorical instead\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "import math\n",
    "\n",
    "# Set index_col to False to avoid pandas thinking that the first column is row indexes (it's age)\n",
    "income = pandas.read_csv(\"income.csv\", index_col=False)\n",
    "\n",
    "print('==================')\n",
    "print('Dataset info before:')\n",
    "print(income.info())\n",
    "print('==============')\n",
    "print()\n",
    "\n",
    "## 3. Converting Categorical Variables ##\n",
    "\n",
    "# Convert a single column from text categories to numbers\n",
    "col = pandas.Categorical.from_array(income[\"workclass\"])\n",
    "income[\"workclass\"] = col.codes\n",
    "\n",
    "categories = ['education', 'marital_status', 'occupation', 'relationship', 'race', 'sex', 'native_country', 'high_income']\n",
    "for category in categories:\n",
    "    cols = pandas.Categorical.from_array(income[category])\n",
    "    income[category] = cols.codes\n",
    "\n",
    "print('==================')\n",
    "print('Dataset info after:')\n",
    "print(income.info())\n",
    "print('==============')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实验"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基本思路是这样的:\n",
    "1. 在每个节点处, 从分支中的对象的所有特征中,通过信息增益找出需要特征, 分出节点, 直到达到要求.\n",
    "2. 将新数据代入模型tree中, 得出预测结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 实验数据 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实验数据如下, data为训练数据, new_data为待预测的数据."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas, numpy, math\n",
    "\n",
    "# Create the data set that we used in the example on the last screen\n",
    "data = pandas.DataFrame([\n",
    "    [0,20,0],\n",
    "    [0,60,2],\n",
    "    [0,40,1],\n",
    "    [1,25,1],\n",
    "    [1,35,2],\n",
    "    [1,55,1]\n",
    "    ])\n",
    "# Assign column names to the data\n",
    "data.columns = [\"high_income\", \"age\", \"marital_status\"]\n",
    "\n",
    "new_data = pandas.DataFrame([\n",
    "    [40,0],\n",
    "    [20,2],\n",
    "    [80,1],\n",
    "    [15,1],\n",
    "    [27,2],\n",
    "    [38,1]\n",
    "    ])\n",
    "# Assign column names to the data\n",
    "new_data.columns = [\"age\", \"marital_status\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 信息熵和信息增益"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**特征的划分以中位数为界划分, 特征值划分先后次序由信息增益决定**\n",
    "\n",
    "划分选择：\n",
    "\n",
    "选择最优划分属性，使决策树的分支结点所包含的样本尽可能属于统一类别，即节点的纯度(purity)越来越高．\n",
    "\n",
    "\n",
    "假定当前样本集合Ｄ中第k类样本所占的比例为$p_k$, \n",
    "\n",
    "**信息熵(information entropy)**:\n",
    "\n",
    "$$Ent(D) = -\\sum_{k=1}^{|y|}p_klog_2p_k$$\n",
    "\n",
    "假设离散属性ａ有Ｖ个可能的取值($a^1, a^2, a^V$).第Ｖ个分支节点包含勒Ｄ中所有在属性ａ上取值为$a^V$的样本，记为$D^V$\n",
    "\n",
    "**信息增益(information gain)**:\n",
    "\n",
    "$$Gain(D, a) = Ent(D) - \\sum_{v=1}^{V}\\frac{D^v}{D}Ent(D^v)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_entropy(column):\n",
    "    \"\"\"\n",
    "    Calculate entropy given a pandas series, list, or numpy array.\n",
    "    \"\"\"\n",
    "    # Compute the counts of each unique value in the column\n",
    "    counts = numpy.bincount(column)\n",
    "    # Divide by the total column length to get a probability\n",
    "    probabilities = counts / len(column)\n",
    "    \n",
    "    # Initialize the entropy to 0\n",
    "    entropy = 0\n",
    "    # Loop through the probabilities, and add each one to the total entropy\n",
    "    for prob in probabilities:\n",
    "        if prob > 0:\n",
    "            entropy += prob * math.log(prob, 2)\n",
    "    \n",
    "    return -entropy\n",
    "\n",
    "\n",
    "def calc_information_gain(data, split_name, target_name):\n",
    "    \"\"\"\n",
    "    Calculate information gain given a data set, column to split on, and target\n",
    "    \"\"\"\n",
    "    # Calculate the original entropy\n",
    "    original_entropy = calc_entropy(data[target_name])\n",
    "    \n",
    "    # Find the median of the column we're splitting\n",
    "    column = data[split_name]\n",
    "    median = column.median()\n",
    "    \n",
    "    # Make two subsets of the data, based on the median\n",
    "    left_split = data[column <= median]\n",
    "    right_split = data[column > median]\n",
    "    \n",
    "    # Loop through the splits and calculate the subset entropies\n",
    "    to_subtract = 0\n",
    "    for subset in [left_split, right_split]:\n",
    "        prob = (subset.shape[0] / data.shape[0]) \n",
    "        to_subtract += prob * calc_entropy(subset[target_name])\n",
    "    \n",
    "    # Return information gain\n",
    "    return original_entropy - to_subtract\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 最大信息增益特征 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "遍历分支节点的对象的所有特征, 找到信息增益最大的特征, 然后依次在分出分支"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column to be splited:\n",
      "marital_status\n"
     ]
    }
   ],
   "source": [
    "## 4. Determining the Column to Split On ##\n",
    "\n",
    "def find_best_column(data, target_name, columns):\n",
    "    # Fill in the logic here to automatically find the column in columns to split on\n",
    "    # data is a dataframe\n",
    "    # target_name is the name of the target variable\n",
    "    # columns is a list of potential columns to split on\n",
    "    information_gain = []\n",
    "    for col in columns:\n",
    "        gain = calc_information_gain(data, col, target_name)\n",
    "        information_gain.append(gain)\n",
    "    highest = max(information_gain)\n",
    "    highest_col = columns[information_gain.index(highest)]\n",
    "    return highest_col\n",
    "\n",
    "# A list of columns to potentially split income with\n",
    "columns = [\"age\", \"marital_status\"]\n",
    "income_split = find_best_column(income, 'high_income', columns)\n",
    "print('Column to be splited:')\n",
    "print(income_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### id3算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "组装成id3算法, **将得到的模型存储在tree中**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'number': 1, 'column': 'age', 'median': 37.5, 'left': {'number': 2, 'column': 'age', 'median': 25.0, 'left': {'number': 3, 'column': 'age', 'median': 22.5, 'left': {'number': 4, 'label': 0}, 'right': {'number': 5, 'label': 1}}, 'right': {'number': 6, 'label': 1}}, 'right': {'number': 7, 'column': 'age', 'median': 55.0, 'left': {'number': 8, 'column': 'age', 'median': 47.5, 'left': {'number': 9, 'label': 0}, 'right': {'number': 10, 'label': 1}}, 'right': {'number': 11, 'label': 0}}}\n"
     ]
    }
   ],
   "source": [
    "## 7. Storing the Tree ##\n",
    "\n",
    "# Create a dictionary to hold the tree  \n",
    "# It has to be outside of the function so we can access it later\n",
    "tree = {}\n",
    "\n",
    "# This list will let us number the nodes  \n",
    "# It has to be a list so we can access it inside the function\n",
    "nodes = []\n",
    "\n",
    "def id3(data, target, columns, tree):\n",
    "    unique_targets = pandas.unique(data[target])\n",
    "    \n",
    "    # Assign the number key to the node dictionary\n",
    "    nodes.append(len(nodes) + 1)\n",
    "    tree[\"number\"] = nodes[-1]\n",
    "\n",
    "    if len(unique_targets) == 1:\n",
    "        # Insert code here that assigns the \"label\" field to the node dictionary\n",
    "        if 0 in unique_targets:\n",
    "            tree['label'] = 0\n",
    "        elif 1 in unique_targets:\n",
    "            tree['label'] = 1\n",
    "        return\n",
    "    \n",
    "    best_column = find_best_column(data, target, columns)\n",
    "    column_median = data[best_column].median()\n",
    "    \n",
    "    # Insert code here that assigns the \"column\" and \"median\" fields to the node dictionary\n",
    "    tree['column'] = best_column\n",
    "    tree['median'] = column_median\n",
    "    \n",
    "    left_split = data[data[best_column] <= column_median]\n",
    "    right_split = data[data[best_column] > column_median]\n",
    "    split_dict = [[\"left\", left_split], [\"right\", right_split]]\n",
    "    \n",
    "    for name, split in split_dict:\n",
    "        tree[name] = {}\n",
    "        id3(split, target, columns, tree[name])\n",
    "\n",
    "# Call the function on our data to set the counters properly\n",
    "id3(data, \"high_income\", [\"age\", \"marital_status\"], tree)\n",
    "\n",
    "print(tree)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 预测新数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将新数据带入模型tree中, 进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Predictions is :\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    1\n",
      "5    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## 10. Making Predictions Automatically ##\n",
    "def predict(tree, row):\n",
    "    if \"label\" in tree:\n",
    "        return tree[\"label\"]\n",
    "    \n",
    "    column = tree[\"column\"]\n",
    "    median = tree[\"median\"]\n",
    "    \n",
    "    # Insert code here to check whether row[column] is less than or equal to median\n",
    "    # If it's less than or equal, return the result of predicting on the left branch of the tree\n",
    "    # If it's greater, return the result of predicting on the right branch of the tree\n",
    "    # Remember to use the return statement to return the result!\n",
    "    if row[column] <= median:\n",
    "        return predict(tree[\"left\"], row)\n",
    "    else:\n",
    "        return predict(tree[\"right\"], row)\n",
    "\n",
    "# Print the prediction for the first row in our data\n",
    "print(predict(tree, data.iloc[0]))\n",
    "\n",
    "## 11. Making Multiple Predictions ##\n",
    "\n",
    "def batch_predict(tree, df):\n",
    "    # Insert your code here\n",
    "    predict_cols = df.apply(lambda x: predict(tree, x), axis = 1)\n",
    "    return predict_cols\n",
    "\n",
    "predictions = batch_predict(tree, new_data)\n",
    "# print('Predictions:', predictions)\n",
    "print('Predictions is :')\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 辅助函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用来输出模型的辅助函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age > 37.5\n",
      "    age > 25.0\n",
      "        age > 22.5\n",
      "            Leaf: Label 0\n",
      "                Leaf: Label 1\n",
      "            Leaf: Label 1\n",
      "        age > 55.0\n",
      "            age > 47.5\n",
      "                Leaf: Label 0\n",
      "                    Leaf: Label 1\n",
      "                Leaf: Label 0\n"
     ]
    }
   ],
   "source": [
    "# ## 8. Printing Labels for a More Attractive Tree ##\n",
    "\n",
    "def print_with_depth(string, depth):\n",
    "    # Add space before a string\n",
    "    prefix = \"    \" * depth\n",
    "    # Print a string, and indent it appropriately\n",
    "    print(\"{0}{1}\".format(prefix, string))\n",
    "    \n",
    "    \n",
    "def print_node(tree, depth):\n",
    "    # Check for the presence of \"label\" in the tree\n",
    "    if \"label\" in tree:\n",
    "        # If found, then this is a leaf, so print it and return\n",
    "        print_with_depth(\"Leaf: Label {0}\".format(tree[\"label\"]), depth)\n",
    "        # This is critical -- without it, you'll get infinite recursion\n",
    "        return\n",
    "    # Print information about what the node is splitting on\n",
    "    print_with_depth(\"{0} > {1}\".format(tree[\"column\"], tree[\"median\"]), depth)\n",
    "    \n",
    "    # Create a list of tree branches\n",
    "    branches = [tree[\"left\"], tree[\"right\"]]\n",
    "        \n",
    "    # Insert code here to recursively call print_node on each branch\n",
    "    # Don't forget to increment depth when you pass it in\n",
    "    for subtree in branches:\n",
    "        depth += 1\n",
    "        print_node(subtree, depth)\n",
    "        \n",
    "\n",
    "print_node(tree, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实战 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 划分数据和模型拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.random.seed(1)\n",
    "\n",
    "# Shuffle the rows  \n",
    "# This permutes the index randomly using numpy.random.permutation\n",
    "# Then, it reindexes the dataframe with the result\n",
    "# The net effect is to put the rows into random order\n",
    "income = income.reindex(numpy.random.permutation(income.index))\n",
    "\n",
    "train_max_row = math.floor(income.shape[0] * .8)\n",
    "train = income.iloc[0:train_max_row, :]\n",
    "test = income.iloc[train_max_row: , :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 2. Using Decision Trees With scikit-learn ##\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# A list of columns to train with\n",
    "# We've already converted all columns to numeric\n",
    "columns = [\"age\", \"workclass\", \"education_num\", \"marital_status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"hours_per_week\", \"native_country\"]\n",
    "\n",
    "# Instantiate the classifier\n",
    "# Set random_state to 1 to make sure the results are consistent\n",
    "clf = DecisionTreeClassifier(random_state=1)\n",
    "clf.fit(income[columns], income['high_income'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型衡量标准"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用AUC(接收者操作特征曲线, 用来衡量二元分类问题的表现[wiki](https://www.wikiwand.com/zh/ROC%E6%9B%B2%E7%BA%BF))参数来衡量模型表现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testset error is: 0.6914060013941348\n",
      "trainset error is: 0.9750761614350801\n"
     ]
    }
   ],
   "source": [
    "## 4. Evaluating Error With AUC ##\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=1)\n",
    "clf.fit(train[columns], train[\"high_income\"])\n",
    "\n",
    "predictions = clf.predict(test[columns])\n",
    "\n",
    "error = roc_auc_score(test['high_income'], predictions)\n",
    "print('testset error is:', error)\n",
    "\n",
    "def auc(data):\n",
    "    predictions = clf.predict(data[columns])\n",
    "    auc = roc_auc_score(data['high_income'], predictions)\n",
    "    return auc\n",
    "\n",
    "## 5. Computing Error on the Training Set ##\n",
    "\n",
    "predictions = clf.predict(train[columns])\n",
    "\n",
    "print('trainset error is:', roc_auc_score(train['high_income'], predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 调参解决过拟合 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上一步明显过拟合, 下面调整树的深度, 最小划分样本数, 进而解决**过拟合**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error with min_samples_split=13\n",
      "train: 0.8476746280562859\n",
      "test: 0.6951852490324495\n",
      "error with min_samples_split=13, max_depth=7\n",
      "train: 0.7487932469002904\n",
      "test: 0.7445508099962767\n",
      "error with max_depth=2, min_samples_split=100\n",
      "train: 0.6624508042161483\n",
      "test: 0.6553138481876499\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Decision trees model from the last screen\n",
    "clf = DecisionTreeClassifier(random_state=1, min_samples_split=13)\n",
    "clf.fit(train[columns], train['high_income'])\n",
    "\n",
    "train_auc = auc(train)\n",
    "test_auc = auc(test)\n",
    "print('error with min_samples_split=13')\n",
    "print('train:', train_auc)\n",
    "print('test:', test_auc)\n",
    "## 8. Tweaking Parameters to Adjust AUC ##\n",
    "\n",
    "# The first decision trees model we trained and tested\n",
    "clf = DecisionTreeClassifier(random_state=1, min_samples_split=13, max_depth=7)\n",
    "clf.fit(train[columns], train[\"high_income\"])\n",
    "predictions = clf.predict(test[columns])\n",
    "test_auc = roc_auc_score(test[\"high_income\"], predictions)\n",
    "\n",
    "train_predictions = clf.predict(train[columns])\n",
    "train_auc = roc_auc_score(train[\"high_income\"], train_predictions)\n",
    "\n",
    "print('error with min_samples_split=13, max_depth=7')\n",
    "print('train:', train_auc)\n",
    "print('test:', test_auc)\n",
    "\n",
    "## 9. Tweaking Tree Depth to Adjust AUC ##\n",
    "\n",
    "# The first decision tree model we trained and tested\n",
    "clf = DecisionTreeClassifier(random_state=1, max_depth=2, min_samples_split=100)\n",
    "clf.fit(train[columns], train[\"high_income\"])\n",
    "predictions = clf.predict(test[columns])\n",
    "test_auc = roc_auc_score(test[\"high_income\"], predictions)\n",
    "\n",
    "train_predictions = clf.predict(train[columns])\n",
    "train_auc = roc_auc_score(train[\"high_income\"], train_predictions)\n",
    "\n",
    "print('error with max_depth=2, min_samples_split=100')\n",
    "print('train:', train_auc)\n",
    "print('test:', test_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 随机森林算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "决策树存在**泛化能力弱**的缺点, 将多棵树结合成随机森林可以改善这一点.\n",
    "\n",
    "基于bagging策略, 随机森林有两种随机:\n",
    "1. 样本的随机\n",
    "2. 特征的随机"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1VS2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc of tree1 0.6878964226062301\n",
      "auc of tree2 0.6759853906508785\n",
      "combine auc of tree1 and tree2 0.7150846804038882\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "columns = [\"age\", \"workclass\", \"education_num\", \"marital_status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"hours_per_week\", \"native_country\"]\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=1, min_samples_leaf=2)\n",
    "clf.fit(train[columns], train[\"high_income\"])\n",
    "\n",
    "clf2 = DecisionTreeClassifier(random_state=1, max_depth=5)\n",
    "clf2.fit(train[columns], train[\"high_income\"])\n",
    "\n",
    "def auc(model):\n",
    "    predictions = model.predict(test[columns])\n",
    "    auc = roc_auc_score(test['high_income'], predictions)\n",
    "    return auc\n",
    "\n",
    "auc1 = auc(clf)\n",
    "auc2 = auc(clf2)\n",
    "\n",
    "print('auc of tree1', auc1)\n",
    "print('auc of tree2', auc2)\n",
    "predictions = clf.predict_proba(test[columns])[:,1]\n",
    "predictions2 = clf2.predict_proba(test[columns])[:,1]\n",
    "mean = (predictions + predictions2) / 2\n",
    "\n",
    "mean = numpy.round(mean)\n",
    "auc = roc_auc_score(test['high_income'], mean)\n",
    "print('combine auc of tree1 and tree2', auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 样本的随机和特征的随机"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结果比上面已有提高"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7329963297474371\n"
     ]
    }
   ],
   "source": [
    "## 6. Introducing Variation With Bagging ##\n",
    "\n",
    "# We'll build 10 trees\n",
    "tree_count = 10\n",
    "\n",
    "# Each \"bag\" will have 60% of the number of original rows\n",
    "bag_proportion = .6\n",
    "\n",
    "predictions = []\n",
    "for i in range(tree_count):\n",
    "    # We select 60% of the rows from train, sampling with replacement\n",
    "    # We set a random state to ensure we'll be able to replicate our results\n",
    "    # We set it to i instead of a fixed value so we don't get the same sample in every loop\n",
    "    # That would make all of our trees the same\n",
    "    bag = train.sample(frac=bag_proportion, replace=True, random_state=i)\n",
    "    \n",
    "    # Fit a decision tree model to the \"bag\"\n",
    "    clf = DecisionTreeClassifier(random_state=1, min_samples_leaf=2)\n",
    "    clf.fit(bag[columns], bag[\"high_income\"])\n",
    "    \n",
    "    # Using the model, make predictions on the test data\n",
    "    predictions.append(clf.predict_proba(test[columns])[:,1])\n",
    "    \n",
    "   \n",
    "final_pred = numpy.zeros(len(test))\n",
    "for pred in predictions:\n",
    "    final_pred += pred\n",
    "\n",
    "final_pred = numpy.round(final_pred/10)\n",
    "\n",
    "auc = roc_auc_score(test['high_income'], final_pred)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 解决过拟合 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train and test error with decision tree:\n",
      "0.8192570489534683\n",
      "0.7139325899284541\n",
      "train and test error with random forest:\n",
      "0.7917047295143252\n",
      "0.7498874343962398\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "## 11. Reducing Overfitting ##\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=1, min_samples_leaf=5)\n",
    "\n",
    "clf.fit(train[columns], train[\"high_income\"])\n",
    "\n",
    "predictions = clf.predict(train[columns])\n",
    "print('train and test error with decision tree:')\n",
    "print(roc_auc_score(train[\"high_income\"], predictions))\n",
    "\n",
    "predictions = clf.predict(test[columns])\n",
    "print(roc_auc_score(test[\"high_income\"], predictions))\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=150, random_state=1, min_samples_leaf=5)\n",
    "clf.fit(train[columns], train[\"high_income\"])\n",
    "\n",
    "predictions = clf.predict(train[columns])\n",
    "print('train and test error with random forest:')\n",
    "print(roc_auc_score(train[\"high_income\"], predictions))\n",
    "\n",
    "predictions = clf.predict(test[columns])\n",
    "print(roc_auc_score(test[\"high_income\"], predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "内容目录",
   "title_sidebar": "目录",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
