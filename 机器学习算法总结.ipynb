{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 传统机器学习算法总结        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gh  2017.11.30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在此总结传统机器学习算法，主要有：\n",
    "\n",
    "一. 监督学习(Supervised Learning):\n",
    "1. 线性回归(Linear Regression)\n",
    "2. 逻辑回归(Logistic Regression)\n",
    "3. 最近紧邻法(K-nearest Neighbors)\n",
    "4. 决策树(Decision Tree)\n",
    "5. 随机森林(Random Forest)\n",
    "6. 支持向量机(Support Vector Machine)\n",
    "7. 朴素贝叶斯(Naive Bayes)\n",
    "\n",
    "二. 非监督学习(Unsupervised Learning):\n",
    "1. K-平均聚类(k-means-clustering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 监督学习 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "监督学习：训练时用label data.\n",
    "问题主要分为两类：\n",
    "<ol>\n",
    "<li>回归问题(Regression)</li>\n",
    "<li>分类问题(Classification)</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 线性回归 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  线性回归为最简单的回归问题，运用线性预测模型来建模。\n",
    "  \n",
    "  定义残差平方和RSS(Residual Sum of Square )如下：\n",
    "  $$RSS = \\sum_{i}(y_{true}-y_{predict})^2$$\n",
    "  计算方法为：Ordinary least square 直接求解; 梯度下降迭代求解。\n",
    "  \n",
    "  算法：\n",
    "  - Given X, want $y_{predict}$,\n",
    "  - Param $w=R^{n}$, $b\\in R$\n",
    "  - Output: $y_{predict}=w^Tt + b$\n",
    "  \n",
    "  如下图："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/lr.png', style=\"width:400px; height:400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 逻辑回归 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  通常用于二元分类(Binary Classification),可理解为一层的神经网络系统。\n",
    "  \n",
    "  算法：\n",
    "  - Given X, want $y_{predict}$, \n",
    "  - Param $w=R^n$, $b\\in R$\n",
    "  - Output: $y_{predict} = \\sigma(w^Tt +b)$ where $\\sigma(z) = \\frac{1}{1 + e^{-z}}$\n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "  Loss function(single sample):\n",
    "  - $L(y', y)=-(ylog(y') + (1-y)log(1-y'))$\n",
    "  \n",
    "  \n",
    "  Cost function(entir train set):\n",
    "  - $J(w, b) = \\frac{1}{m}\\sum_{i=1}^{n}L(y'^{(i)}, y^{(i)})$\n",
    "  \n",
    "  \n",
    "  计算方法：\n",
    "  - 梯度下降法\n",
    "  \n",
    "  \n",
    "  对于Multiclass classification 问题： one-over-many approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 最近紧邻法 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k个最近紧邻中最常见的分类决定了赋予该对象的类别。\n",
    "\n",
    "优点：\n",
    "    简单\n",
    "    \n",
    "缺点：\n",
    "    无法给出数据内在含义"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 决策树 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可用于回归和分类问题。\n",
    "\n",
    "通过计算信息论中的信息熵(entropy), 进而计算出信息所得(infomation gain)来决定信息树的分叉。即通过计算所能得到的最高信息所得，来决定树节点的分割。\n",
    "\n",
    "优点：\n",
    "感念简单，可解释性强，输出结果容易理解．\n",
    "\n",
    "缺点：过拟合，信息确实处理起来比较困难"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 随机森林 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随机森林是多个决策树的合体(ensemble of decision tree), 即通过向决策树中引入方差使整体得到一个更好的结果。集成算法，随机选取不同特征和训练样本，生成大量决策树．准确性提高．\n",
    "\n",
    "主要有两种方法：\n",
    "- Bagging (subset of data)\n",
    "- random features subset\n",
    "\n",
    "\n",
    "应用场景：\n",
    "\n",
    "    数据维度相对较低，对准确度有较高要求"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 支持向量机"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "？？？？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 朴素贝叶斯"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "？？？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 非监督学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 K-平均算法 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按照最小欧式距离分配到最近的聚类，使用迭代优化的算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
